{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First part is to read multiple .csv's and concat them. Can skip if you already have the full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalise data sets\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "def scaleColumns(df, cols_to_scale):\n",
    "    for col in cols_to_scale:\n",
    "        df[col] = pd.DataFrame(min_max_scaler.fit_transform(pd.DataFrame(df[col])),columns=[col])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/media/joao/TOSHIBA EXT/Background_samples/CSV_data\"\n",
    "\n",
    "all_Signal = glob.glob(path + \"/LQ_*.csv\")\n",
    "all_ttbar = glob.glob(path + \"/ttbar_*.csv\")\n",
    "all_WW = glob.glob(path + \"/WW_*.csv\")\n",
    "all_ZZ = glob.glob(path + \"/ZZ_*.csv\")\n",
    "all_ZW = glob.glob(path + \"/ZW_*.csv\")\n",
    "all_Zplusjets = glob.glob(path + \"/Z_plus_jets_*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vars_to_use = ['pt_l1', 'pt_l2', 'E_l1', 'E_l2', 'DeltaR_l1l2', 'DeltaPhi_l1l2', 'DeltaTheta_l1l2',\n",
    "               'cos_l1l2', 'DeltaTheta_l1l2_CM', 'M_l1l2', 'b2_l1l2', 'b4_l1l2', 'SpinCorr_Rcosl1',\n",
    "               'SpinCorr_Rcosl2', 'SpinCorr_Ncosl1','SpinCorr_Ncosl2', 'xs_weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_Signal = []\n",
    "li_ttbar = []\n",
    "li_WW = []\n",
    "li_ZZ = []\n",
    "li_ZW = []\n",
    "li_Zplusjets = []\n",
    "\n",
    "#Signal\n",
    "for filename in all_Signal:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li_Signal.append(df)\n",
    "\n",
    "Signal = pd.concat(li_Signal, axis=0, ignore_index=True)\n",
    "Signal = Signal[Vars_to_use]\n",
    "\n",
    "#ttbar\n",
    "for filename in all_ttbar:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li_ttbar.append(df)\n",
    "\n",
    "ttbar = pd.concat(li_ttbar, axis=0, ignore_index=True)\n",
    "ttbar = ttbar[Vars_to_use]\n",
    "\n",
    "#WW\n",
    "for filename in all_WW:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li_WW.append(df)\n",
    "\n",
    "WW = pd.concat(li_WW, axis=0, ignore_index=True)\n",
    "WW = WW[Vars_to_use]\n",
    "\n",
    "#ZZ\n",
    "for filename in all_ZZ:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li_ZZ.append(df)\n",
    "\n",
    "ZZ = pd.concat(li_ZZ, axis=0, ignore_index=True)\n",
    "ZZ = ZZ[Vars_to_use]\n",
    "\n",
    "#ZW\n",
    "for filename in all_ZW:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li_ZW.append(df)\n",
    "\n",
    "ZW = pd.concat(li_ZW, axis=0, ignore_index=True)\n",
    "ZW = ZW[Vars_to_use]\n",
    "\n",
    "#Z plus jets\n",
    "for filename in all_Zplusjets:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li_Zplusjets.append(df)\n",
    "\n",
    "Z_plus_jets = pd.concat(li_Zplusjets, axis=0, ignore_index=True)\n",
    "Z_plus_jets = Z_plus_jets[Vars_to_use]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal (fb): 0.23040527818452006\n",
      "Diboson (fb): 32191.469264447667\n",
      "ttbar (fb): 75269.65792903882\n",
      "Z plus jets (fb): 10819462.000118723\n"
     ]
    }
   ],
   "source": [
    "#Cross sections: Sums all values in collumn 'weight' in each data frame\n",
    "#Divided by the number of samples. I have batches of 10 samples, each with 100K events,\n",
    "#so I must divide the result by 30\n",
    "\n",
    "#ttbar\n",
    "ttbar_N3LO = 988.57\n",
    "ttbar_LO = 93.32\n",
    "ttbar_new_weight = (ttbar['xs_weight']*ttbar_N3LO)/ttbar_LO\n",
    "xsec_N3LO_ttbar = (ttbar_new_weight.sum()*1000)/10\n",
    "\n",
    "#Z plus jets\n",
    "Zjets_NNLO = 6.33*1e4\n",
    "Zjets_LO = 4128.0\n",
    "Zjets_new_weight = (Z_plus_jets['xs_weight']*Zjets_NNLO)/Zjets_LO\n",
    "xsec_NNLO_Zjets = (Zjets_new_weight.sum()*1000)/10\n",
    "\n",
    "#VV +jets. Cross sections for each individual process \n",
    "#WW + jets\n",
    "WW_NLO = 124.31\n",
    "WW_LO = 77.22\n",
    "WW_new_weight = (WW['xs_weight']*WW_NLO)/WW_LO\n",
    "xsec_NNLO_WW = (WW_new_weight.sum()*1000)/10\n",
    "\n",
    "#WZ + jets\n",
    "ZW_NLO = 51.82\n",
    "ZW_LO = 0.9827\n",
    "ZW_new_weight = (ZW['xs_weight']*ZW_NLO)/ZW_LO\n",
    "xsec_NNLO_ZW = (ZW_new_weight.sum()*1000)/10\n",
    "\n",
    "#ZZ + jets\n",
    "ZZ_NLO = 17.72\n",
    "ZZ_LO = 0.03654\n",
    "ZZ_new_weight = (ZZ['xs_weight']*ZZ_NLO)/ZZ_LO\n",
    "xsec_NNLO_ZZ = (ZZ_new_weight.sum()*1000)/10\n",
    "\n",
    "print(\"Signal (fb):\", (Signal['xs_weight'].sum()*1000))\n",
    "print(\"Diboson (fb):\", (xsec_NNLO_ZZ + xsec_NNLO_ZW + xsec_NNLO_WW))\n",
    "print(\"ttbar (fb):\", xsec_N3LO_ttbar)\n",
    "print(\"Z plus jets (fb):\", xsec_NNLO_Zjets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttbar['xs_weight'] = ttbar_new_weight\n",
    "Z_plus_jets['xs_weight'] = Zjets_new_weight\n",
    "WW['xs_weight'] = WW_new_weight\n",
    "ZW['xs_weight'] = ZW_new_weight\n",
    "ZZ['xs_weight'] = ZZ_new_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat diboson data\n",
    "Diboson = pd.concat([WW, ZZ, ZW], axis=0, ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 False\n",
      "1 False\n",
      "2 False\n",
      "3 False\n"
     ]
    }
   ],
   "source": [
    "List = [Diboson, Signal, ttbar, Z_plus_jets]\n",
    "#Check for NaNs\n",
    "for i in range(0,len(List)):\n",
    "    print(i, List[i].isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save data\n",
    "Signal.to_csv('/media/joao/TOSHIBA EXT/Machine_learning/Data/Signal_1p5TeV.csv',sep=',',index=False)\n",
    "Diboson.to_csv('/media/joao/TOSHIBA EXT/Machine_learning/Data/Diboson.csv',sep=',',index=False)\n",
    "ttbar.to_csv('/media/joao/TOSHIBA EXT/Machine_learning/Data/ttbar.csv',sep=',',index=False)\n",
    "Z_plus_jets.to_csv('/media/joao/TOSHIBA EXT/Machine_learning/Data/Z_plus_jets.csv',sep=',',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read CSV data already concated correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Signal = pd.read_csv('/media/joao/TOSHIBA EXT/Machine_learning/Data/Signal_1p5TeV.csv', sep=',')\n",
    "Diboson = pd.read_csv('/media/joao/TOSHIBA EXT/Machine_learning/Data/Diboson.csv', sep=',')\n",
    "ttbar = pd.read_csv('/media/joao/TOSHIBA EXT/Machine_learning/Data/ttbar.csv', sep=',')\n",
    "Z_plus_jets = pd.read_csv('/media/joao/TOSHIBA EXT/Machine_learning/Data/Z_plus_jets.csv', sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop weight for the machine learning\n",
    "for i in [Signal, Diboson, ttbar, Z_plus_jets]:\n",
    "    i.drop(['xs_weight'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity check. Make sure all labels for the kinematics are correct\n",
    "#If result is false, then there is something wrong with the tabular data\n",
    "Signal = Signal.reindex(sorted(Signal.columns), axis=1)\n",
    "Diboson = Diboson.reindex(sorted(Diboson.columns), axis=1)\n",
    "ttbar = ttbar.reindex(sorted(ttbar.columns), axis=1)\n",
    "Z_plus_jets = Z_plus_jets.reindex(sorted(Z_plus_jets.columns), axis=1)\n",
    "\n",
    "list(Signal)==list(Diboson)==list(ttbar)==list(Z_plus_jets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add classification labels\n",
    "Signal['signal'] = 0\n",
    "Diboson['signal'] = 1\n",
    "ttbar['signal'] = 2\n",
    "Z_plus_jets['signal'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DeltaPhi_l1l2', 'DeltaR_l1l2', 'DeltaTheta_l1l2',\n",
       "       'DeltaTheta_l1l2_CM', 'E_l1', 'E_l2', 'M_l1l2', 'SpinCorr_Ncosl1',\n",
       "       'SpinCorr_Ncosl2', 'SpinCorr_Rcosl1', 'SpinCorr_Rcosl2', 'b2_l1l2',\n",
       "       'b4_l1l2', 'cos_l1l2', 'pt_l1', 'pt_l2', 'signal'], dtype='<U18')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get labels\n",
    "np.transpose(list(Signal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([Signal, Diboson, ttbar, Z_plus_jets],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalise the dataset\n",
    "analysis = scaleColumns(combined, ['DeltaPhi_l1l2', 'DeltaR_l1l2', 'DeltaTheta_l1l2',\n",
    "                                   'DeltaTheta_l1l2_CM', 'E_l1', 'E_l2', 'M_l1l2', 'SpinCorr_Ncosl1',\n",
    "                                   'SpinCorr_Ncosl2', 'SpinCorr_Rcosl1', 'SpinCorr_Rcosl2', 'b2_l1l2',\n",
    "                                   'b4_l1l2', 'cos_l1l2', 'pt_l1', 'pt_l2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = analysis.drop(['signal'], axis=1)\n",
    "y = analysis['signal']\n",
    "#Divide into train and test/val data. 80% for train, 20% for validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1505133, 16)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   6118, 1129094,  194402,  175519])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resample data using SMOTE algorithm\n",
    "X_resampled, y_resampled = SMOTE().fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4516376, 16)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save data in numpy format\n",
    "np.savez('/media/joao/TOSHIBA EXT/Machine_learning/Data/X_train_1p5TeV.npz', x=X_resampled, y=y_resampled)\n",
    "np.savez('/media/joao/TOSHIBA EXT/Machine_learning/Data/X_test_1p5TeV.npz', x=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
